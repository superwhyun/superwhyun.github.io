---
title: 문서요약 서비스 비교 v.2022

categories: information
tags: [summarize, document, ai]
Created: 2022년 6월 19일 오전 10:42
Last Edited Time: 2022년 7월 17일 오전 3:52
---

인공지능을 이용한 다양한 문서 요약(summary) 서비스가 제공 중이다. 국내에서도 기사를 요약하는 서비스를 제공하는 기업이 있으나 일반인에게 사용이 공개된 것 같지는 않다. 영어로 된 내용을 요약해주는 대표적인 서비스 2개를 비교해 본다.

## Summari

[Summari - Free Text Summary Tool That Helps You Read More](https://www.summari.com/)

- 특징
    - Support
        - Web Extension
            - 크롬 브라우저 익스텐셔 지원
            - 파이어폭스 지원하지 않음
        - App
            - 앱에서 공유 기능으로 바로 보낼 수 있으며, 시간이 오래 걸리는 경우에는  ‘save later’ 기능을 이용해 나중에 볼 수 있다.
        - Share
            - 요약된 결과에 대해 웹 링크를 제공해 주기 때문에 다른 사람과 공유가 용이하다.
    - 요금
        - 현재 시범 기간이라 무료이나 곧 유료화 될 듯 하다.
    - 장점
        - 결과를 D&D로 복사해서 사용하기 좋다. 특히 Notion과 결합할 때 바로 복사가 된다.
        - 생각보다 안되는 사이트들이 제법 있다.
    - 단점
        - 살짝 오래 걸린다.
        

## TLDR This

- 특징
    - Support
        - Web Extension
            - 파이어폭스 애드 온 지원함
            - 크롬 브라우저 익스텐션 지원
        - App
            - 있겠지
        - Share
            - 되겠지
    - 요금
        
        ![Untitled](/assets/images/2022-07-17-문서요약-서비스-비교-v-2022/Untitled.png)
        
        - 
    - 장점
        - 결과를 D&D로 복사해서 사용하기 좋다. 특히 Notion과 결합할 때 바로 복사가 된다.
        - 요약의 디테일을 조정할 수 있다.
            
            ![Untitled](/assets/images/2022-07-17-문서요약-서비스-비교-v-2022/Untitled%201.png)
            
        - 
    - 단점
        - 무료버전은 요약이 심플하다. 단점이라고 보기는 그렇고…
            - 제공되는 고급버전 토큰 10개는 순삭된다. 동일 페이지에 대해 옵션 하나만 바꿔도 토큰 사용된다.
        - 결과물의 품질이 그닥?
        - 무료버전은 10개의 paraphrase만 지원함.
            - 즉, 요약이 중간에 멈춘다는 얘기…
            - 짧은 글에만 사용할 수 있다
    - 장점
        - 빠르다.
        

## Comparison

아래 링크의 기사에 대해 각 서비스별 결과를 비교해 보겠다.

[Meta has built a massive new language AI-and it's giving it away for free](https://www.technologyreview.com/2022/05/03/1051691/meta-ai-large-language-model-gpt3-ethics-huggingface-transparency/)

<aside>
💡 한줄요약: 속도는 TLDR이 더 빨랐으나, 결과물의 품질은 Summari가 더 나은 것 같다.

</aside>

### Summari 결과

---

SUMMARY | SAVE 6 MIN

## Meta has built a massive new language AI—and it’s giving it away for free

### Meta's AI lab has created a massive new language model that shares both the remarkable abilities and harmful flaws of OpenAI's pioneering neural network GPT-3

- And in an unprecedented move for Big Tech, it is giving it away to researchers-together with details about how it was built and trained.
- Large language models-powerful programs that can generate paragraphs of text and mimic human conversation-have become one of the hottest trends in AI in the last couple of years.

### Culture clash

- Meta is a company that has said little about how the algorithms behind Facebook and Instagram work and has a reputation for burying unfavorable findings by its own in-house research teams
- A big reason for the different approach by Meta AI is Pineau herself
- She has been pushing for more transparency in AI for a number of years
- Ultimately, Pineau wants to change how we judge AI

### Weighing the risks

- Margaret Mitchell, one of the AI ethics researchers Google forced out in 2020, who is now at Hugging Face, sees the release of OPT as a positive move.
- But there are limits to transparency
- Has the language model been tested with sufficient rigor?
- Do the foreseeable benefits outweigh the foreseeable harms-such as the generation of misinformation, or racist and misogynistic language?

### TLDR This 결과

---

## **Meta has built a massive new language AI—and it’s giving it away for free**

- Meta’s move is the first time that a fully trained large language model will
be made available to any researcher who wants to study it.
- The more open models the better,” he says.
- Large language models—powerful programs that can generate paragraphs of text
and mimic human conversation—have become one of the hottest trends in AI in the last couple of years.
- We know the gap that exists between universities and industry in terms of the ability to build these models.
- It is also releasing its code and a logbook that documents the training process.
- With 175 billion parameters (the values in a neural network that get tweaked during training), OPT is the same size as GPT-3.